ggplot(train, aes(as.numeric(OverallQual), SalePrice)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
geom_smooth(se = F, col = 2) + # Local regression named LOESS
labs(title = "SalePrice ~ OverallQual, with linear and local regression")
lm(SalePrice ~ OverallQual, data = train) %>% summary()
lm(SalePrice ~ factor(OverallQual), data = train) %>% summary()
#Changing overallQual to a factor since it perform better in model
train <- train %>% mutate(OverallQual = factor(OverallQual))
test <- test %>% mutate(OverallQual = factor(OverallQual))
#Comparing factors of GarageCars in linear model
lm(SalePrice ~ GarageCars, data = train) %>% summary()
lm(SalePrice ~ factor(GarageCars), data = train) %>% summary()
# ------ Code Removed as Level 5 not available for prediction between train and test - keeping it numeric --------
#Changing GarageCars to a factor since it perform better in model
#train <- train %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#test <- test %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#train %>% summary()
set.seed(100)
inTrain <- createDataPartition(y=train$SalePrice, p = 0.70, list=FALSE)
train_set <- train[inTrain,]
test_set <- train[-inTrain,]
train_set %>% head()
test_set %>% head()
# Fit model
model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train_set)
#model coefficients
model %>% summary()
# Get predictions for the validation fold
predictions <- predict(model, newdata = test_set)
rmse <- function(observed, predicted) sqrt(mean((observed - predicted)^2))
R2 <- function(observed, predicted){
TSS <- sum((observed - mean(observed))^2)
RSS <- sum((observed - predicted)^2)
1- RSS/TSS
}
rmse(test_set$SalePrice, predictions)
R2(test_set$SalePrice, predictions)
final_model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train)
final_prediction <- predict(final_model, newdata = test)
# Trial 1 - "OverallQual"  "Neighborhood" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
# Trial 2 - "OverallQual"  "LotFrontage" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
train <- train_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF", "SalePrice")]
test_read <- read_csv("kaggle test.csv")
train_read <- read_csv("kaggle train.csv")
summary(train)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
test_read <- read_csv("kaggle test.csv")
train_read <- read_csv("kaggle train.csv")
summary(train_read)
#Use decision tree to find important features
tree_model <- rpart(SalePrice ~ ., data = train_read)
importance <- round(tree_model$variable.importance, 2)
top5_features <- names(importance[order(-importance)])[1:5]
# Display feature importance
print(top5_features)
# Trial 1 - "OverallQual"  "Neighborhood" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
# Trial 2 - "OverallQual"  "LotFrontage" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
train <- train_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF", "SalePrice")]
test <- test_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF")]
#Trial 1 - Neighborhood = factor(Neighborhood),
#Trial 2 - LotFrontage = replace_na(LotFrontage, 0)
train <- train %>% mutate(Neighborhood = factor(Neighborhood), GarageCars = replace_na(GarageCars, 0), TotalBsmtSF = replace_na(TotalBsmtSF, 0), KitchenQual = factor(KitchenQual))
test <- test %>% mutate(Neighborhood = factor(Neighborhood), GarageCars = replace_na(GarageCars, 0), TotalBsmtSF = replace_na(TotalBsmtSF, 0), KitchenQual = factor(KitchenQual))
# Compare test and train data
train %>% summary()
test %>% summary()
train %>%
ggplot(aes(factor(OverallQual), SalePrice)) +
geom_boxplot() +
labs(title = "SalePrice ~ OverallQual")
ggplot(train, aes(as.numeric(OverallQual), SalePrice)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
geom_smooth(se = F, col = 2) + # Local regression named LOESS
labs(title = "SalePrice ~ OverallQual, with linear and local regression")
lm(SalePrice ~ OverallQual, data = train) %>% summary()
lm(SalePrice ~ factor(OverallQual), data = train) %>% summary()
#Changing overallQual to a factor since it perform better in model
train <- train %>% mutate(OverallQual = factor(OverallQual))
test <- test %>% mutate(OverallQual = factor(OverallQual))
#Comparing factors of GarageCars in linear model
lm(SalePrice ~ GarageCars, data = train) %>% summary()
lm(SalePrice ~ factor(GarageCars), data = train) %>% summary()
# ------ Code Removed as Level 5 not available for prediction between train and test - keeping it numeric --------
#Changing GarageCars to a factor since it perform better in model
#train <- train %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#test <- test %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#train %>% summary()
set.seed(100)
inTrain <- createDataPartition(y=train$SalePrice, p = 0.70, list=FALSE)
train_set <- train[inTrain,]
test_set <- train[-inTrain,]
train_set %>% head()
test_set %>% head()
# Fit model
model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train_set)
#model coefficients
model %>% summary()
# Get predictions for the validation fold
predictions <- predict(model, newdata = test_set)
rmse <- function(observed, predicted) sqrt(mean((observed - predicted)^2))
R2 <- function(observed, predicted){
TSS <- sum((observed - mean(observed))^2)
RSS <- sum((observed - predicted)^2)
1- RSS/TSS
}
rmse(test_set$SalePrice, predictions)
R2(test_set$SalePrice, predictions)
final_model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train)
final_prediction <- predict(final_model, newdata = test)
final_prediction %>% head()
final_model %>% summary()
round(rmse(test_set$SalePrice, predictions),2)
round(R2(test_set$SalePrice, predictions),2)
set.seed(100)
# Split the data 70-30 for cross validation.
inTrain <- createDataPartition(y=train$SalePrice, p = 0.70, list=FALSE)
train_set <- train[inTrain,]
test_set <- train[-inTrain,]
train_set %>% head()
test_set %>% head()
# Fit model
model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train_set)
#model coefficients
model %>% summary()
# Get predictions for the validation fold
predictions <- predict(model, newdata = test_set)
rmse <- function(observed, predicted) sqrt(mean((observed - predicted)^2))
R2 <- function(observed, predicted){
TSS <- sum((observed - mean(observed))^2)
RSS <- sum((observed - predicted)^2)
1- RSS/TSS
}
#RMSE
round(rmse(test_set$SalePrice, predictions),2)
#R2
round(R2(test_set$SalePrice, predictions),2)
final_model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train)
final_model %>% summary()
#Read data
test_read <- read_csv("kaggle test.csv")
submission = cbind(ID = test$, prediction_df)
test %>% summary()
test_read %>% summary()
submission = cbind(Id = test$Id, prediction_df)
#convert final prediction vector to dataframe
prediction_df <- data.frame(SalePrice = final_prediction)
submission = cbind(Id = test$Id, prediction_df)
summary(prediction_df)
summary(prediction_df$count)
summary(prediction_df %>% count)
submission %>% count()
test_read %>% count()
summary(prediction_df %>% count)
test %>% count()
prediction_df <- data.frame(SalePrice = final_prediction)
submission = cbind(Id = test_read$Id, prediction_df)
submission %>% head()
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
submission = cbind(Id = test_read$Id, prediction_df) %>% mutate(SalePrice = replace_na(SalePrice, mean(SalePrice)))
submission %>% head()
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
submission = cbind(Id = test_read$Id, prediction_df) %>% mutate(SalePrice = replace_na(SalePrice, 0))
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
# Load packages
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
#Read data
test_read <- read_csv("kaggle test.csv")
train_read <- read_csv("kaggle train.csv")
summary(train_read)
#Use decision tree to find important features
tree_model <- rpart(SalePrice ~ ., data = train_read)
importance <- round(tree_model$variable.importance, 2)
top5_features <- names(importance[order(-importance)])[1:5]
# Display feature importance
print(top5_features)
# Trial 1 - "OverallQual"  "Neighborhood" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
# Trial 2 - "OverallQual"  "LotFrontage" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
# Fixed the Trial 1 variables as it gave the best result.
train <- train_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF", "SalePrice")]
test <- test_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF")]
#Trial 1 - Neighborhood = factor(Neighborhood),
#Trial 2 - LotFrontage = replace_na(LotFrontage, 0)
train <- train %>% mutate(Neighborhood = factor(Neighborhood), GarageCars = replace_na(GarageCars, 0), TotalBsmtSF = replace_na(TotalBsmtSF, 0), KitchenQual = factor(KitchenQual))
test <- test %>% mutate(Neighborhood = factor(Neighborhood), GarageCars = replace_na(GarageCars, 0), TotalBsmtSF = replace_na(TotalBsmtSF, 0), KitchenQual = factor(KitchenQual))
# Compare test and train data
train %>% summary()
test %>% summary()
#Compare the relation between overall quality and sale price
train %>%
ggplot(aes(factor(OverallQual), SalePrice)) +
geom_boxplot() +
labs(title = "SalePrice ~ OverallQual")
ggplot(train, aes(as.numeric(OverallQual), SalePrice)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
geom_smooth(se = F, col = 2) + # Local regression named LOESS
labs(title = "SalePrice ~ OverallQual, with linear and local regression")
# Train the model to find the best fit.
lm(SalePrice ~ OverallQual, data = train) %>% summary()
lm(SalePrice ~ factor(OverallQual), data = train) %>% summary()
#Changing overallQual to a factor since it perform better in model
train <- train %>% mutate(OverallQual = factor(OverallQual))
test <- test %>% mutate(OverallQual = factor(OverallQual))
#Comparing factors of GarageCars in linear model
lm(SalePrice ~ GarageCars, data = train) %>% summary()
lm(SalePrice ~ factor(GarageCars), data = train) %>% summary()
# ------ Code Removed as Level 5 not available for prediction between train and test - keeping it numeric --------
#Changing GarageCars to a factor since it perform better in model
#train <- train %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#test <- test %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#train %>% summary()
set.seed(100)
# Split the data 70-30 for cross validation.
inTrain <- createDataPartition(y=train$SalePrice, p = 0.70, list=FALSE)
train_set <- train[inTrain,]
test_set <- train[-inTrain,]
train_set %>% head()
test_set %>% head()
# Fit model
model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train_set)
#model coefficients
model %>% summary()
# Get predictions for the validation fold
predictions <- predict(model, newdata = test_set)
rmse <- function(observed, predicted) sqrt(mean((observed - predicted)^2))
R2 <- function(observed, predicted){
TSS <- sum((observed - mean(observed))^2)
RSS <- sum((observed - predicted)^2)
1- RSS/TSS
}
#RMSE
round(rmse(test_set$SalePrice, predictions),2)
#R2
round(R2(test_set$SalePrice, predictions),2)
final_model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train)
final_model %>% summary()
final_prediction <- predict(final_model, newdata = test)
#convert final prediction vector to dataframe
prediction_df <- data.frame(SalePrice = final_prediction)
submission = cbind(Id = test_read$Id, prediction_df) %>% mutate(SalePrice = replace_na(SalePrice, 0))
submission %>% head()
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
#convert final prediction vector to dataframe
prediction_df <- data.frame(SalePrice = final_prediction)
submission = cbind(Id = test_read$Id, prediction_df) %>% mutate(SalePrice = replace_na(SalePrice, 180921))
submission %>% head()
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
# Load packages
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
#Read data
test_read <- read_csv("kaggle test.csv")
train_read <- read_csv("kaggle train.csv")
summary(train_read)
#Use decision tree to find important features
tree_model <- rpart(SalePrice ~ ., data = train_read)
importance <- round(tree_model$variable.importance, 2)
top5_features <- names(importance[order(-importance)])[1:5]
# Display feature importance
print(top5_features)
# Trial 1 - "OverallQual"  "Neighborhood" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
# Trial 2 - "OverallQual"  "LotFrontage" "GarageCars"   "KitchenQual"  "TotalBsmtSF"
# Fixed the Trial 1 variables as it gave the best result.
train <- train_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF", "SalePrice")]
test <- test_read[,c("OverallQual", "Neighborhood", "GarageCars", "KitchenQual",  "TotalBsmtSF")]
#Trial 1 - Neighborhood = factor(Neighborhood),
#Trial 2 - LotFrontage = replace_na(LotFrontage, 0)
train <- train %>% mutate(Neighborhood = factor(Neighborhood), GarageCars = replace_na(GarageCars, 0), TotalBsmtSF = replace_na(TotalBsmtSF, 0), KitchenQual = factor(KitchenQual))
test <- test %>% mutate(Neighborhood = factor(Neighborhood), GarageCars = replace_na(GarageCars, 0), TotalBsmtSF = replace_na(TotalBsmtSF, 0), KitchenQual = factor(KitchenQual))
# Compare test and train data
train %>% summary()
test %>% summary()
#Compare the relation between overall quality and sale price
train %>%
ggplot(aes(factor(OverallQual), SalePrice)) +
geom_boxplot() +
labs(title = "SalePrice ~ OverallQual")
ggplot(train, aes(as.numeric(OverallQual), SalePrice)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
geom_smooth(se = F, col = 2) + # Local regression named LOESS
labs(title = "SalePrice ~ OverallQual, with linear and local regression")
# Train the model to find the best fit.
lm(SalePrice ~ OverallQual, data = train) %>% summary()
lm(SalePrice ~ factor(OverallQual), data = train) %>% summary()
#Changing overallQual to a factor since it perform better in model
train <- train %>% mutate(OverallQual = factor(OverallQual))
test <- test %>% mutate(OverallQual = factor(OverallQual))
#Comparing factors of GarageCars in linear model
lm(SalePrice ~ GarageCars, data = train) %>% summary()
lm(SalePrice ~ factor(GarageCars), data = train) %>% summary()
# ------ Code Removed as Level 5 not available for prediction between train and test - keeping it numeric --------
#Changing GarageCars to a factor since it perform better in model
#train <- train %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#test <- test %>% mutate(GarageCars = factor(GarageCars, levels = c(0,1,2,3,4,5)))
#train %>% summary()
set.seed(100)
# Split the data 70-30 for cross validation.
inTrain <- createDataPartition(y=train$SalePrice, p = 0.70, list=FALSE)
train_set <- train[inTrain,]
test_set <- train[-inTrain,]
train_set %>% head()
test_set %>% head()
# Fit model
model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train_set)
#model coefficients
model %>% summary()
# Get predictions for the validation fold
predictions <- predict(model, newdata = test_set)
rmse <- function(observed, predicted) sqrt(mean((observed - predicted)^2))
R2 <- function(observed, predicted){
TSS <- sum((observed - mean(observed))^2)
RSS <- sum((observed - predicted)^2)
1- RSS/TSS
}
#RMSE
round(rmse(test_set$SalePrice, predictions),2)
#R2
round(R2(test_set$SalePrice, predictions),2)
final_model <- lm(SalePrice ~ OverallQual + Neighborhood + GarageCars + KitchenQual + TotalBsmtSF, data = train)
final_model %>% summary()
final_prediction <- predict(final_model, newdata = test)
#convert final prediction vector to dataframe
prediction_df <- data.frame(SalePrice = final_prediction)
submission = cbind(Id = test_read$Id, prediction_df) %>% mutate(SalePrice = replace_na(SalePrice, 180921))
submission %>% head()
#Write to csv file
write.csv(submission, "submission.csv", row.names = FALSE)
library(quanteda)
a<-"This Residence Marriott is not fancy."
b<-"It was clean, good service and suite style rooms;"
c<-"However, it's a little older than some Residence Marriotts's
I've stayed at and probably could use an update soon."
d<-"You can count on Residence Marriott to deliver on its promises"
library(quanteda)
hotel_demo<-c(a,b,c,d)
hotel_demo_token <- quanteda::tokens(hotel_demo,
remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE, remove_hyphens = TRUE)
hotel_demo_token <- quanteda::tokens(hotel_demo,
remove_numbers = TRUE, remove_punct = TRUE,
remove_symbols = TRUE)
hotel_demo_token<-dfm(hotel_demo_token)
hotel_demo_token1<-as.matrix(hotel_demo_token)
hotel_demo_token1[1:4,1:10]
x1<-"My stay at the Residence Marriott was terrible and location was bad"
x2<-"The highlight of my stay at the Residence Marriott was its service"
x3<-"Service at the hotel was very good"
x1<-dfm(x1)
x1<-dfm(tokens(x1))
x2<-dfm(tokens(x2))
x3<-dfm(tokens(x3))
x1
hotel_demo_token1[1:4,1:10]
# compute similarity between reviews x1 and x2
library(quanteda.textstats)# for computing stats between different texts
textstat_simil(
x1,
x2,
margin = ("documents"),
method = ( "cosine"),
)
# compute similarity between reviews x2 and x3
textstat_simil(
x2,
x3,
margin = ("documents"),
method = ( "cosine"),
)
tfidf<-data.frame(dfm_tfidf(hotel_demo_token, scheme_tf = "prop", scheme_df = "inverse", base = 10))
tfidf[1:4,1:5]
tfidf<-data.frame(dfm_tfidf(hotel_demo_token, scheme_tf = "prop", scheme_df = "inverse", base = 10))
tfidf <- dfm_tfidf(hotel_demo_token, scheme_tf = "prop", scheme_df = "inverse", base = 10) %>% convert(to = "data.frame")
tfidf[1:4,1:5]
View(tfidf)
setwd("C:/Users/sachi/OneDrive - University of Utah/Sem3/MKTG6640 TA/Week 1/")
# Load up the .CSV data and explore.
library(tidyverse)
hotel_raw <- read_csv("hotel-reviews.csv")
setwd("C:/Users/sachi/OneDrive - University of Utah/Sem3/MKTG6640 TA/Week 1/")
getwd()
setwd("/Users/u1452118/Documents/OneDrive - University of Utah/Sem3/MKTG6640 TA/Week 1/")
hotel_raw <- read_csv("hotel-reviews.csv")
glimpse(hotel_raw)
sum(!complete.cases(hotel_raw)) # checking the number of incomplete cases
hotel_raw$Is_Response <- as.factor(hotel_raw$Is_Response)
hotel_raw$Device_Used <- as.factor(hotel_raw$Device_Used)
hotel_raw$Browser_Used <- as.factor(hotel_raw$Browser_Used)
hotel_raw <- hotel_raw %>%
mutate(hotel_name = case_when(str_detect(Description, "Hilton")~ "Hilton",
str_detect(Description, "Hyatt")~ "Hyatt",
str_detect(Description, "Marriott")~ "Marriott"))
hotel_sub <- hotel_raw %>% filter(hotel_name=="Hilton"|hotel_name=="Hyatt"|hotel_name=="Marriott")
hotel_raw <- hotel_raw %>%
mutate(hotel_name = case_when(str_detect(Description, "Hilton")~ "Hilton",
str_detect(Description, "Hyatt")~ "Hyatt",
str_detect(Description, "Marriott")~ "Marriott"))
View(hotel_sub)
hotel_sub %>%
count(Is_Response)%>%
mutate(freq=n/sum(n))
hotel_sub %>%
group_by(hotel_name) %>%
count(Is_Response)%>%
mutate(freq=n/sum(n))
hotel_sub<-hotel_sub %>%
mutate(ReviewLength=nchar(Description))
library(quanteda)
data_corpus_hotelsub <- corpus(hotel_sub, text_field = "Description")# for subsequent analysis
hotel_sub%>%
group_by( hotel_name, Device_Used) %>%
summarise(AvLength=mean(ReviewLength))
library(ggplot2)
ggplot(hotel_sub, aes(x = ReviewLength, fill = Is_Response)) +
geom_histogram(binwidth = 5) +  facet_wrap(~ hotel_name)+
labs(y = "Review Count", x = "Length of Review",
title = "Distribution of Review Lengths with Class Labels")
library(polite)
bow("https://www.rottentomatoes.com")
library(polite)
library(rvest)
library(polite)
bow("https://www.rottentomatoes.com")
library(polite)
library(rvest)
wiki_cb <-
bow("https://en.wikipedia.org/wiki/Consumer_behaviour") %>%
scrape()
wiki_cb # to test if we have properly downloaded the webpage
View(wiki_cb)
wikitext<-wiki_cb %>%
html_nodes("p") %>% #from rvest package
html_text()
wikitext[2] # output from p2
wikihead<-wiki_cb %>%
html_nodes("h2") %>% #from rvest package
html_text()
head(wikihead)
ul_wiki <- wiki_cb %>%
html_nodes("ul") %>%
html_text()
ul_wiki[2]
section_of_wikipedia<-html_node(wiki_cb, xpath='//*[@id="mw-content-text"]/div/table[3]')
percy_table<-html_table(section_of_wikipedia)
head(percy_table)
results <-
wiki_cb  %>%
html_table()
head(results[[3]])
body_nodes <- wiki_cb %>%
html_nodes('body') %>%
html_children() # for looking at nested elements
body_nodes %>%
html_children()
all_text<-wiki_cb %>%
html_nodes("div") %>%
html_text2()
View(section_of_wikipedia)
View(percy_table)
all_text<-wiki_cb %>%
html_nodes("div") %>%
html_text2()
# Clean up the plain text by removing extra spaces, newlines, etc.
clean_text <- gsub("[[:space:]]+", " ", all_text)
clean_text <- gsub("\n+", "\n", clean_text)
clean_text <- trimws(clean_text)
# Print the cleaned up text using the command below.
cat(clean_text)
library(stringr)
clean_text <- gsub("(f|ht)tps?://\\S+", "", clean_text)
clean_text <- gsub("\\.mw-parser-output[^{]*\\{[^}]*\\}", "", clean_text)
clean_text <- gsub("\\^\\s*", "\n", clean_text) # Add newlines after each reference
top20movies <-
bow("https://editorial.rottentomatoes.com/guide/100-best-classic-movies/") %>%
scrape()
title_html <- html_nodes(top20movies,'.article_movie_title a')
#Converting the ranking data to text
titletext <- html_text(title_html)
library(polite)
bow("https://amazon.com/s?k=best+seller+book+list&page=1")
library(ralger)
my_link <- "https://amazon.com/s?k=best+seller+book+list&page=1"
my_node<-".a-color-base.a-text-normal"# selector gadget will give these element ID
best_books <- scrap(link = my_link, node = my_node)
head(best_books,5)
my_link <- "https://amazon.com/s?k=best+seller+book+list&page=1"
my_node<-".a-color-base.a-text-normal"# selector gadget will give these element ID
best_books <- scrap(link = my_link, node = my_node)
base_link <- "https://amazon.com/s?k=best+seller+book+list&page="
links <- paste0(base_link, 1:7) # there are 7 pages
node<-".a-color-base.a-text-normal"
all_books<-scrap(links, node)
